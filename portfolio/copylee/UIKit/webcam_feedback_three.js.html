<html>
<head>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/85/three.min.js"></script>
</head>
<body>

<video id="monitor" autoplay style="display:none; width: 320x; height: 320px;"></video>

<div id="canvasLayers"   style="position: absolute; left:480px; top:160px;  width:240px; height:160px; float:right">


<canvas id="videoCanvas" width="0" height="0" style="z-index: 1; position: absolute; left:0px; top:0px; opacity:0.41;"></canvas>


<script>navigator.getUserMedia = navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia;
window.URL = window.URL || window.webkitURL;

var camvideo = document.getElementById('monitor');

	if (!navigator.getUserMedia)
	{
		document.getElementById('messageError').innerHTML =
			'Sorry. <code>navigator.getUserMedia()</code> is not available.';
	}
	navigator.getUserMedia({video: true}, gotStream, noStream);

function gotStream(stream)
{
	if (window.URL)
	{   camvideo.src = window.URL.createObjectURL(stream);   }
	else // Opera
	{   camvideo.src = stream;   }

	camvideo.onerror = function(e)
	{   stream.stop();   };

	stream.onended = noStream;
}

function noStream(e)
{
	var msg = 'No camera available.';
	if (e.code == 1)
	{   msg = 'User denied access to use camera.';   }
	document.getElementById('errorMessage').textContent = msg;
}

    </script>


	<script id="fragShader" type="shader-code">

		uniform vec2 res;
		uniform sampler2D bufferTexture;
		uniform sampler2D videoTexture;
		uniform float time;
		void main() {
			vec2 st = gl_FragCoord.xy / res;
			vec2 uv = st;
		
		 //
     // uv *= 1.003;
      	uv *= 0.997;

			vec4 sum = texture2D(bufferTexture, uv);
			vec4 src = texture2D(videoTexture, uv);
      
      //
			//sum.rgb = mix(sum.rbg, src.rgb, 0.01);
			//sum.rgb = mix(sum.rbg, src.rgb, 0.0077);
			sum.rgb = mix(sum.rbg, src.rgb, 0.0377);
			gl_FragColor = sum;

		 }
	</script>


	<script>
		var scene;
		var camera;
		var renderer;
		var bufferScene;
		var textureA;
		var textureB;
		var bufferMaterial;
		var plane;
		var bufferObject;
		var finalMaterial;
		var quad;
    var video;
    var videoTexture;
    var videoCanvas = document.getElementById( 'videoCanvas' );
    var videoContext = videoCanvas.getContext( '2d' );

		var composer;



		function sceneSetup(){

			scene = new THREE.Scene();
			var width = window.innerWidth;
			var height = window.innerHeight;
			camera = new THREE.OrthographicCamera( width / - 2, width / 2, height / 2, height / - 2, 1, 1000 );
			//camera.position.z = 12;
			camera.position.z = 2;

			renderer = new THREE.WebGLRenderer();
			renderer.setSize( window.innerWidth, window.innerHeight );
			document.body.appendChild( renderer.domElement );

		}

		function videoTextureSetup() {

			video = document.getElementById( 'monitor' );
			videoTexture = new THREE.VideoTexture( video );

			videoTexture.minFilter = THREE.LinearFilter;
			videoTexture.magFilter = THREE.LinearFilter;
			videoTexture.format = THREE.RGBFormat;

			//videoContext.translate(320, 0);
	        videoContext.scale(-1, 1);
	        videoContext.fillStyle = '#005337';
	        videoContext.fillRect( 0, 0, videoCanvas.width, videoCanvas.height );
		}

		function bufferTextureSetup(){
			//Create buffer scene
			bufferScene = new THREE.Scene();
			//Create 2 buffer textures
			textureA = new THREE.WebGLRenderTarget( window.innerWidth, window.innerHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.LinearFilter});
			textureB = new THREE.WebGLRenderTarget( window.innerWidth, window.innerHeight, { minFilter: THREE.LinearFilter, magFilter: THREE.LinearFilter} );
			//Pass textureA to shader
			bufferMaterial = new THREE.ShaderMaterial( {
				uniforms: {
				 bufferTexture: { type: "t", value: textureA.texture },
				 res : {type: 'v2',value:new THREE.Vector2(window.innerWidth,window.innerHeight)},
				 //Keeps the resolution
				 videoTexture: {type: "t", value: videoTexture },
				// time: {type:"f",value:Math.random()*Math.PI*+Math.PI}
				 time: {type:"f",value:Math.random()*Math.PI*7+Math.PI}
				},
				fragmentShader: document.getElementById( 'fragShader' ).innerHTML
			} );
			plane = new THREE.PlaneBufferGeometry( window.innerWidth, window.innerHeight );
			bufferObject = new THREE.Mesh( plane, bufferMaterial );
			bufferScene.add(bufferObject);

			//Draw textureB to screen
			finalMaterial =  new THREE.MeshBasicMaterial({map: textureB});
			quad = new THREE.Mesh( plane, finalMaterial );
			scene.add(quad);
		}

		//Initialize the Threejs scene
		sceneSetup();

		//Setup the frame buffer/texture we're going to be rendering to instead of the screen
		videoTextureSetup();
		bufferTextureSetup();
    
    
    //
    //
    //
    //
    
    
         document.addEventListener( 'mousedown', function( e ) {
           
           
           uv *= 0.891;


         }
                                                                                                       

            );
    
        
                                   
    
    
                                   
    
    
    
    

		function render() {

		  requestAnimationFrame( render );
		  //Draw to textureB
		  renderer.render(bufferScene,camera,textureB,true);
		  //Swap textureA and B
		  var t = textureA;
		  textureA = textureB;
		  textureB = t;
		  quad.material.map = textureB.texture;
		  bufferMaterial.uniforms.bufferTexture.value = textureA.texture;

		  //Update time
		  bufferMaterial.uniforms.time.value += 0.0033;
		 // bufferMaterial.uniforms.time.value += 0.01;
		 renderer.render( scene, camera );

		}

		render();

	</script>
</body>
</html>
